{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爬取的页数500\n",
      "第1页正常采集\n",
      "第2页正常采集\n",
      "第3页正常采集\n",
      "第4页正常采集\n",
      "第5页正常采集\n",
      "第6页正常采集\n",
      "第7页正常采集\n",
      "第8页正常采集\n",
      "第9页正常采集\n",
      "第10页正常采集\n",
      "第11页正常采集\n",
      "第12页正常采集\n",
      "第13页正常采集\n",
      "第14页正常采集\n",
      "第15页正常采集\n",
      "第16页正常采集\n",
      "第17页正常采集\n",
      "第18页正常采集\n",
      "第19页正常采集\n",
      "第20页正常采集\n",
      "第21页正常采集\n",
      "第22页正常采集\n",
      "第23页正常采集\n",
      "第24页正常采集\n",
      "第25页正常采集\n",
      "第26页正常采集\n",
      "第27页正常采集\n",
      "第28页正常采集\n",
      "第29页正常采集\n",
      "第30页正常采集\n",
      "第31页正常采集\n",
      "第32页正常采集\n",
      "第33页正常采集\n",
      "第34页正常采集\n",
      "第35页正常采集\n",
      "第36页正常采集\n",
      "第37页正常采集\n",
      "第38页正常采集\n",
      "第39页正常采集\n",
      "第40页正常采集\n",
      "第41页正常采集\n",
      "第42页正常采集\n",
      "第43页正常采集\n",
      "第44页正常采集\n",
      "第45页正常采集\n",
      "第46页正常采集\n",
      "第47页正常采集\n",
      "第48页正常采集\n",
      "第49页正常采集\n",
      "第50页正常采集\n",
      "第51页正常采集\n",
      "第52页正常采集\n",
      "第53页正常采集\n",
      "第54页正常采集\n",
      "第55页正常采集\n",
      "第56页正常采集\n",
      "第57页正常采集\n",
      "第58页正常采集\n",
      "第59页正常采集\n",
      "第60页正常采集\n",
      "第61页正常采集\n",
      "第62页正常采集\n",
      "第63页正常采集\n",
      "第64页正常采集\n",
      "第65页正常采集\n",
      "第66页正常采集\n",
      "第67页正常采集\n",
      "第68页正常采集\n",
      "第69页正常采集\n",
      "第70页正常采集\n",
      "第71页正常采集\n",
      "第72页正常采集\n",
      "第73页正常采集\n",
      "第74页正常采集\n",
      "第75页正常采集\n",
      "第76页正常采集\n",
      "第77页正常采集\n",
      "第78页正常采集\n",
      "第79页正常采集\n",
      "第80页正常采集\n",
      "第81页正常采集\n",
      "第82页正常采集\n",
      "第83页正常采集\n",
      "第84页正常采集\n",
      "第85页正常采集\n",
      "第86页正常采集\n",
      "第87页正常采集\n",
      "第88页正常采集\n",
      "第89页正常采集\n",
      "第90页正常采集\n",
      "第91页正常采集\n",
      "第92页正常采集\n",
      "第93页正常采集\n",
      "第94页正常采集\n",
      "第95页正常采集\n",
      "第96页正常采集\n",
      "第97页正常采集\n",
      "第98页正常采集\n",
      "第99页正常采集\n",
      "第100页正常采集\n",
      "第101页正常采集\n",
      "第102页正常采集\n",
      "第103页正常采集\n",
      "第104页正常采集\n",
      "第105页正常采集\n",
      "第106页正常采集\n",
      "第107页正常采集\n",
      "第108页正常采集\n",
      "第109页正常采集\n",
      "第110页正常采集\n",
      "第111页正常采集\n",
      "第112页正常采集\n",
      "第113页正常采集\n",
      "第114页正常采集\n",
      "第115页正常采集\n",
      "第116页正常采集\n",
      "第117页正常采集\n",
      "第118页正常采集\n",
      "第119页正常采集\n",
      "第120页正常采集\n",
      "第121页正常采集\n",
      "第122页正常采集\n",
      "第123页正常采集\n",
      "第124页正常采集\n",
      "第125页正常采集\n",
      "第126页正常采集\n",
      "第127页正常采集\n",
      "第128页正常采集\n",
      "第129页正常采集\n",
      "第130页正常采集\n",
      "第131页正常采集\n",
      "第132页正常采集\n",
      "第133页正常采集\n",
      "第134页正常采集\n",
      "第135页正常采集\n",
      "第136页正常采集\n",
      "第137页正常采集\n",
      "第138页正常采集\n",
      "第139页正常采集\n",
      "第140页正常采集\n",
      "第141页正常采集\n",
      "第142页正常采集\n",
      "第143页正常采集\n",
      "第144页正常采集\n",
      "第145页正常采集\n",
      "第146页正常采集\n",
      "第147页正常采集\n",
      "第148页正常采集\n",
      "第149页正常采集\n",
      "第150页正常采集\n",
      "第151页正常采集\n",
      "第152页正常采集\n",
      "第153页正常采集\n",
      "第154页正常采集\n",
      "第155页正常采集\n",
      "第156页正常采集\n",
      "第157页正常采集\n",
      "第158页正常采集\n",
      "第159页正常采集\n",
      "第160页正常采集\n",
      "第161页正常采集\n",
      "第162页正常采集\n",
      "第163页正常采集\n",
      "第164页正常采集\n",
      "第165页正常采集\n",
      "第166页正常采集\n",
      "第167页正常采集\n",
      "第168页正常采集\n",
      "第169页正常采集\n",
      "第170页正常采集\n",
      "第171页正常采集\n",
      "第172页正常采集\n",
      "第173页正常采集\n",
      "第174页正常采集\n",
      "第175页正常采集\n",
      "第176页正常采集\n",
      "第177页正常采集\n",
      "第178页正常采集\n",
      "第179页正常采集\n",
      "第180页正常采集\n",
      "第181页正常采集\n",
      "第182页正常采集\n",
      "第183页正常采集\n",
      "第184页正常采集\n",
      "第185页正常采集\n",
      "第186页正常采集\n",
      "第187页正常采集\n",
      "第188页正常采集\n",
      "第189页正常采集\n",
      "第190页正常采集\n",
      "第191页正常采集\n",
      "第192页正常采集\n",
      "第193页正常采集\n",
      "第194页正常采集\n",
      "第195页正常采集\n",
      "第196页正常采集\n",
      "第197页正常采集\n",
      "第198页正常采集\n",
      "第199页正常采集\n",
      "第200页正常采集\n",
      "第201页正常采集\n",
      "第202页正常采集\n",
      "第203页正常采集\n",
      "第204页正常采集\n",
      "第205页正常采集\n",
      "第206页正常采集\n",
      "第207页正常采集\n",
      "第208页正常采集\n",
      "第209页正常采集\n",
      "第210页正常采集\n",
      "第211页正常采集\n",
      "第212页正常采集\n",
      "第213页正常采集\n",
      "第214页正常采集\n",
      "第215页正常采集\n",
      "第216页正常采集\n",
      "第217页正常采集\n",
      "第218页正常采集\n",
      "第219页正常采集\n",
      "第220页正常采集\n",
      "第221页正常采集\n",
      "第222页正常采集\n",
      "第223页正常采集\n",
      "第224页正常采集\n",
      "第225页正常采集\n",
      "第226页正常采集\n",
      "第227页正常采集\n",
      "第228页正常采集\n",
      "第229页正常采集\n",
      "第230页正常采集\n",
      "第231页正常采集\n",
      "第232页正常采集\n",
      "第233页正常采集\n",
      "第234页正常采集\n",
      "第235页正常采集\n",
      "第236页正常采集\n",
      "第237页正常采集\n",
      "第238页正常采集\n",
      "第239页正常采集\n",
      "第240页正常采集\n",
      "第241页正常采集\n",
      "第242页正常采集\n",
      "第243页正常采集\n",
      "第244页正常采集\n",
      "第245页正常采集\n",
      "第246页正常采集\n",
      "第247页正常采集\n",
      "第248页正常采集\n",
      "第249页正常采集\n",
      "第250页正常采集\n",
      "第251页正常采集\n",
      "第252页正常采集\n",
      "第253页正常采集\n",
      "第254页正常采集\n",
      "第255页正常采集\n",
      "第256页正常采集\n",
      "第257页正常采集\n",
      "第258页正常采集\n",
      "第259页正常采集\n",
      "第260页正常采集\n",
      "第261页正常采集\n",
      "第262页正常采集\n",
      "第263页正常采集\n",
      "第264页正常采集\n",
      "第265页正常采集\n",
      "第266页正常采集\n",
      "第267页正常采集\n",
      "第268页正常采集\n",
      "第269页正常采集\n",
      "第270页正常采集\n",
      "第271页正常采集\n",
      "第272页正常采集\n",
      "第273页正常采集\n",
      "第274页正常采集\n",
      "第275页正常采集\n",
      "第276页正常采集\n",
      "第277页正常采集\n",
      "第278页正常采集\n",
      "第279页正常采集\n",
      "第280页正常采集\n",
      "第281页正常采集\n",
      "第282页正常采集\n",
      "第283页正常采集\n",
      "第284页正常采集\n",
      "第285页正常采集\n",
      "第286页正常采集\n",
      "第287页正常采集\n",
      "第288页正常采集\n",
      "第289页正常采集\n",
      "第290页正常采集\n",
      "第291页正常采集\n",
      "第292页正常采集\n",
      "第293页正常采集\n",
      "第294页正常采集\n",
      "第295页正常采集\n",
      "第296页正常采集\n",
      "第297页正常采集\n",
      "第298页正常采集\n",
      "第299页正常采集\n",
      "第300页正常采集\n",
      "第301页正常采集\n",
      "第302页正常采集\n",
      "第303页正常采集\n",
      "第304页正常采集\n",
      "第305页正常采集\n",
      "第306页正常采集\n",
      "第307页正常采集\n",
      "第308页正常采集\n",
      "第309页正常采集\n",
      "第310页正常采集\n",
      "第311页正常采集\n",
      "第312页正常采集\n",
      "第313页正常采集\n",
      "第314页正常采集\n",
      "第315页正常采集\n",
      "第316页正常采集\n",
      "第317页正常采集\n",
      "第318页正常采集\n",
      "第319页正常采集\n",
      "第320页正常采集\n",
      "第321页正常采集\n",
      "第322页正常采集\n",
      "第323页正常采集\n",
      "第324页正常采集\n",
      "第325页正常采集\n",
      "第326页正常采集\n",
      "第327页正常采集\n",
      "第328页正常采集\n",
      "第329页正常采集\n",
      "第330页正常采集\n",
      "第331页正常采集\n",
      "第332页正常采集\n",
      "第333页正常采集\n",
      "第334页正常采集\n",
      "第335页正常采集\n",
      "第336页正常采集\n",
      "第337页正常采集\n",
      "第338页正常采集\n",
      "第339页正常采集\n",
      "第340页正常采集\n",
      "第341页正常采集\n",
      "第342页正常采集\n",
      "第343页正常采集\n",
      "第344页正常采集\n",
      "第345页正常采集\n",
      "第346页正常采集\n",
      "第347页正常采集\n",
      "第348页正常采集\n",
      "第349页正常采集\n",
      "第350页正常采集\n",
      "第351页正常采集\n",
      "第352页正常采集\n",
      "第353页正常采集\n",
      "第354页正常采集\n",
      "第355页正常采集\n",
      "第356页正常采集\n",
      "第357页正常采集\n",
      "第358页正常采集\n",
      "第359页正常采集\n",
      "第360页正常采集\n",
      "第361页正常采集\n",
      "第362页正常采集\n",
      "第363页正常采集\n",
      "第364页正常采集\n",
      "第365页正常采集\n",
      "第366页正常采集\n",
      "第367页正常采集\n",
      "第368页正常采集\n",
      "第369页正常采集\n",
      "第370页正常采集\n",
      "第371页正常采集\n",
      "第372页正常采集\n",
      "第373页正常采集\n",
      "第374页正常采集\n",
      "第375页正常采集\n",
      "第376页正常采集\n",
      "第377页正常采集\n",
      "第378页正常采集\n",
      "第379页正常采集\n",
      "第380页正常采集\n",
      "第381页正常采集\n",
      "第382页正常采集\n",
      "第383页正常采集\n",
      "第384页正常采集\n",
      "第385页正常采集\n",
      "第386页正常采集\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7fc900768810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mworkbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lagouzp2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-7fc900768810>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         }\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0minfo_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo_result\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"第%s页正常采集\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-7fc900768810>\u001b[0m in \u001b[0;36mget_json\u001b[0;34m(url, datas)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"application/x-www-form-urlencoded;charset = UTF-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     }\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import xlwt\n",
    "import time\n",
    "\n",
    "def get_json(url,datas):\n",
    "    my_headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.71 Safari/537.36\",\n",
    "        \"Referer\": \"https://www.lagou.com/jobs/list_machine%20learning?city=%E5%85%A8%E5%9B%BD&cl=false&fromSearch=true&labelWords=&suginput=\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded;charset = UTF-8\"\n",
    "    }\n",
    "    time.sleep(5)\n",
    "    ses = requests.session()\n",
    "    ses.headers.update(my_headers)\n",
    "    ses.get(\"https://www.lagou.com/jobs/list_machine%20learning?city=%E5%85%A8%E5%9B%BD&cl=false&fromSearch=true&labelWords=&suginput=\")\n",
    "    content = ses.post(url=url,data=datas)\n",
    "    result = content.json()\n",
    "    info = result['content']['positionResult']['result']\n",
    "    info_list = []\n",
    "    for job in info:\n",
    "        information = []\n",
    "        information.append(job['positionId'])\n",
    "        information.append(job['city'])\n",
    "        information.append(job['companyFullName'])\n",
    "        information.append(job['companyLabelList'])\n",
    "        information.append(job['district'])  \n",
    "        information.append(job['education'])  \n",
    "        information.append(job['firstType'])  \n",
    "        information.append(job['formatCreateTime'])  \n",
    "        information.append(job['positionName'])  \n",
    "        information.append(job['salary'])  \n",
    "        information.append(job['workYear']) \n",
    "        info_list.append(information)\n",
    "    return info_list\n",
    "def main():\n",
    "    page = int(input('爬取的页数'))\n",
    "    info_result = []\n",
    "    title = ['岗位id', '城市', '公司全名', '福利待遇', '工作地点', '学历要求', '工作类型', '发布时间', '职位名称', '薪资', '工作年限']\n",
    "    info_result.append(title)\n",
    "    for x in range(1,page+1):\n",
    "        url = 'https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false'\n",
    "        datas = {\n",
    "            'first': 'false',\n",
    "            'pn': x,\n",
    "            'kd': 'machine learning',\n",
    "        }\n",
    "        try:\n",
    "            info = get_json(url,datas)\n",
    "            info_result = info_result + info\n",
    "            print(\"第%s页正常采集\"%x)\n",
    "        except Exception as msg:\n",
    "            print(\"第%s页出现问题\"%x)\n",
    "        \n",
    "        workbook = xlwt.Workbook(encoding='utf-8')\n",
    "        worksheet = workbook.add_sheet('lagouzp', cell_overwrite_ok=True)\n",
    "        for i, row in enumerate(info_result):\n",
    "            for j, col in enumerate(row):\n",
    "                worksheet.write(i, j, col)\n",
    "        workbook.save('lagouzp2.csv')\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import xlwt\n",
    "import time\n",
    "\n",
    "def get_json(url,datas):\n",
    "    my_headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36\",\n",
    "        \"Referer\": \"https://www.lagou.com/jobs/list_Python?city=%E5%85%A8%E5%9B%BD&cl=false&fromSearch=true&labelWords=&suginput=\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded;charset = UTF-8\"\n",
    "    }\n",
    "    time.sleep(5)\n",
    "    ses = requests.session()\n",
    "    ses.headers.update(my_headers)\n",
    "    ses.get(\"https://www.lagou.com/jobs/list_Python?city=%E5%85%A8%E5%9B%BD&cl=false&fromSearch=true&labelWords=&suginput=\")\n",
    "    content = ses.post(url=url,data=datas)\n",
    "    result = content.json()\n",
    "    info = result['content']['positionResult']['result']\n",
    "    info_list = []\n",
    "    for job in info:\n",
    "        information = []\n",
    "        information.append(job['positionId'])\n",
    "        information.append(job['city'])\n",
    "        information.append(job['companyFullName'])\n",
    "        information.append(job['companyLabelList'])\n",
    "        information.append(job['district'])  \n",
    "        information.append(job['education'])  \n",
    "        information.append(job['firstType'])  \n",
    "        information.append(job['formatCreateTime'])  \n",
    "        information.append(job['positionName'])  \n",
    "        information.append(job['salary'])  \n",
    "        information.append(job['workYear']) \n",
    "        info_list.append(information)\n",
    "    return info_list\n",
    "def main():\n",
    "    page = int(input('爬取的页数'))\n",
    "    info_result = []\n",
    "    title = ['岗位id', '城市', '公司全名', '福利待遇', '工作地点', '学历要求', '工作类型', '发布时间', '职位名称', '薪资', '工作年限']\n",
    "    info_result.append(title)\n",
    "    for x in range(1,page+1):\n",
    "        url = 'https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false'\n",
    "        datas = {\n",
    "            'first': 'false',\n",
    "            'pn': x,\n",
    "            'kd': 'python',\n",
    "        }\n",
    "        try:\n",
    "            info = get_json(url,datas)\n",
    "            info_result = info_result + info\n",
    "            print(\"第%s页正常采集\"%x)\n",
    "        except Exception as msg:\n",
    "            print(\"第%s页出现问题\"%x)\n",
    "        \n",
    "        workbook = xlwt.Workbook(encoding='utf-8')\n",
    "        worksheet = workbook.add_sheet('lagouzp', cell_overwrite_ok=True)\n",
    "        for i, row in enumerate(info_result):\n",
    "            for j, col in enumerate(row):\n",
    "                worksheet.write(i, j, col)\n",
    "        workbook.save('lagouzp1.xls')\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
